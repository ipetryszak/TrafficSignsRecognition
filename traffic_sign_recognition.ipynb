{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traffic_sign_recognition.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skorpiom/traffic_sign_rec/blob/master/traffic_sign_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfjxHdfIeA4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf sample_data\n",
        "!rm -rf train_and_valid_signs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WyfMCT8tZdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.io.parsers import read_csv\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "np.set_printoptions(precision = 6, suppress = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMSPpKQze6zy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "f44c0f7c-f7ff-44f4-fef1-3f181db5a2bb"
      },
      "source": [
        "!wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB-Training_fixed.zip\n",
        "!unzip -q GTSRB-Training_fixed.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-28 11:13:08--  https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB-Training_fixed.zip\n",
            "Resolving sid.erda.dk (sid.erda.dk)... 130.225.104.13\n",
            "Connecting to sid.erda.dk (sid.erda.dk)|130.225.104.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 187490228 (179M) [application/zip]\n",
            "Saving to: ‘GTSRB-Training_fixed.zip’\n",
            "\n",
            "GTSRB-Training_fixe 100%[===================>] 178.80M  18.2MB/s    in 11s     \n",
            "\n",
            "2019-12-28 11:13:19 (16.4 MB/s) - ‘GTSRB-Training_fixed.zip’ saved [187490228/187490228]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKtwh6NQtbct",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f23f3dc4-430d-4ffc-91e5-f9161838824a"
      },
      "source": [
        "base_dir = './GTSRB/Training'\n",
        "raw_no_of_files = {}\n",
        "classes = []\n",
        "for n in range(0,43):\n",
        "  if n<10:\n",
        "    classes.append(\"0000\"+str(n))\n",
        "  else:\n",
        "    classes.append(\"000\"+str(n))\n",
        "\n",
        "for dir in classes:\n",
        "  raw_no_of_files[dir] = len(os.listdir(os.path.join(base_dir,dir)))\n",
        "\n",
        "raw_no_of_files.items()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('00000', 151), ('00001', 1501), ('00002', 1501), ('00003', 961), ('00004', 1321), ('00005', 1261), ('00006', 301), ('00007', 961), ('00008', 961), ('00009', 991), ('00010', 1351), ('00011', 901), ('00012', 1411), ('00013', 1441), ('00014', 541), ('00015', 421), ('00016', 301), ('00017', 751), ('00018', 811), ('00019', 151), ('00020', 241), ('00021', 241), ('00022', 271), ('00023', 361), ('00024', 181), ('00025', 1021), ('00026', 421), ('00027', 181), ('00028', 361), ('00029', 181), ('00030', 301), ('00031', 541), ('00032', 181), ('00033', 481), ('00034', 301), ('00035', 811), ('00036', 271), ('00037', 151), ('00038', 1381), ('00039', 211), ('00040', 241), ('00041', 181), ('00042', 181)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDk2VufBzHX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = './train_and_valid_signs'\n",
        "dirs_train = []\n",
        "dirs_valid = []\n",
        "\n",
        "train_dir = os.path.join(data_dir,'train') #katalog treningowy\n",
        "valid_dir = os.path.join(data_dir,'valid') #katalog walidacyjny\n",
        "\n",
        "for n in range(0,43):\n",
        "  dirs_train.append(os.path.join(train_dir,classes[n])) #sciezki z katalogami docelowymi zbior treningowy\n",
        "\n",
        "for n in range(0,43):\n",
        "  dirs_valid.append(os.path.join(valid_dir,classes[n])) #sciezki z katalogami docelowymi zbior walidacyjny\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "  os.mkdir(data_dir)\n",
        "  \n",
        "for directory in (train_dir,valid_dir):\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)\n",
        "\n",
        "for directory in dirs_train:\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)\n",
        "\n",
        "for directory in dirs_valid:\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5q60TwSrB3L",
        "colab_type": "text"
      },
      "source": [
        "#DISPLAY INDICATED SIGN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ATvJIdIeJHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "189d82fd-bd7b-4d9b-d175-5ef81060b5dc"
      },
      "source": [
        "img_path = os.path.join('./GTSRB','Training','00000','00001_00010.ppm')\n",
        "print(img_path)\n",
        "img = image.load_img(img_path)\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(img)\n",
        "plt.grid(False)\n",
        "plt.axis(False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./GTSRB/Training/00000/00001_00010.ppm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 35.5, 34.5, -0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEYAAABECAYAAAA85kOPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQn3GdKH/BmqWm/FvbuoeAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu6phs3CilvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "41efedb7-2b69-44b7-a7c8-dbe7f7bff400"
      },
      "source": [
        "sign_fnames = []\n",
        "for ind in range(0,43):\n",
        "  sign_fnames.append(os.listdir(os.path.join(base_dir,classes[ind])))  \n",
        "\n",
        "print('00000 liczba obiektow: ',len(sign_fnames[0]))\n",
        "print('00001 liczba obiektow: ',len(sign_fnames[1]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00000 liczba obiektow:  151\n",
            "00001 liczba obiektow:  1501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVuWmzKiqw39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,fname in enumerate(sign_fnames):\n",
        "  for j,name in enumerate(fname):\n",
        "    if j<=0.8*int(np.floor(len(fname))):\n",
        "      src = os.path.join(base_dir,classes[i],name)\n",
        "      dst = os.path.join(dirs_train[i],name)\n",
        "      shutil.copyfile(src,dst)\n",
        "    if 0.8*int(np.floor(len(fname))) < j <= len(fname):\n",
        "      src = os.path.join(base_dir,classes[i],name)\n",
        "      dst = os.path.join(dirs_valid[i],name)\n",
        "      shutil.copyfile(src,dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ42aaDc84nH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "9773f5d6-5f07-43c8-afd3-16df4a42619e"
      },
      "source": [
        "print('00000 zbior treningowy ',len(os.listdir(dirs_train[0])))\n",
        "print('00000 zbior walidacyjny ',len(os.listdir(dirs_valid[0])))\n",
        "\n",
        "print('00001 zbior treningowy ',len(os.listdir(dirs_train[1])))\n",
        "print('00001 zbior walidacyjny ',len(os.listdir(dirs_valid[1])))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00000 zbior treningowy  121\n",
            "00000 zbior walidacyjny  30\n",
            "00001 zbior treningowy  1201\n",
            "00001 zbior walidacyjny  300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCWoQ5IY_R6U",
        "colab_type": "text"
      },
      "source": [
        "#AUGMENTACJA DANYCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3naRxdW84cN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "cdac183d-0573-4307-ae8b-99d80b62822d"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range = 40,\n",
        "    rescale = 1./255.,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest'\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale = 1./255.) #przeskalowanie danych\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
        "                                                    target_size=(32,32),\n",
        "                                                    batch_size = 8,\n",
        "                                                    class_mode='categorical')\n",
        "valid_generator = train_datagen.flow_from_directory(directory = valid_dir,\n",
        "                                                    target_size=(32,32),\n",
        "                                                    batch_size = 8,\n",
        "                                                    class_mode='categorical')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 21319 images belonging to 43 classes.\n",
            "Found 5321 images belonging to 43 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp0doLYEQZA2",
        "colab_type": "text"
      },
      "source": [
        "#BUDOWA MODELU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyBNveOWNq_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "592c73c1-0649-46eb-f8a4-ffe008ad1250"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(3,3),activation='relu',input_shape=(32, 32, 3)))\n",
        "model.add(layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units=1024, activation='relu'))\n",
        "model.add(layers.Dense(units=43, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_63 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_57 (MaxPooling (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_66 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 43)                44075     \n",
            "=================================================================\n",
            "Total params: 2,383,083\n",
            "Trainable params: 2,383,083\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcmPligmU4ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQeEJIniXv1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf logs\n",
        "!mkdir logs\n",
        "tensorboard = TensorBoard(log_dir='logs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3bHf7yaXxbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "596edc27-8d74-4e1c-dd45-43a9acfee2d4"
      },
      "source": [
        "history = model.fit_generator(generator=train_generator,\n",
        "                              epochs = 30,\n",
        "                              validation_data = valid_generator,\n",
        "                              callbacks = [tensorboard])"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 2665 steps, validate for 666 steps\n",
            "Epoch 1/30\n",
            "2665/2665 [==============================] - 33s 13ms/step - loss: 2.8807 - accuracy: 0.1909 - val_loss: 2.4456 - val_accuracy: 0.2983\n",
            "Epoch 2/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 2.1600 - accuracy: 0.3546 - val_loss: 1.8616 - val_accuracy: 0.4227\n",
            "Epoch 3/30\n",
            "2665/2665 [==============================] - 32s 12ms/step - loss: 1.7366 - accuracy: 0.4573 - val_loss: 1.5320 - val_accuracy: 0.5129\n",
            "Epoch 4/30\n",
            "2665/2665 [==============================] - 32s 12ms/step - loss: 1.4866 - accuracy: 0.5248 - val_loss: 1.4312 - val_accuracy: 0.5499\n",
            "Epoch 5/30\n",
            "2665/2665 [==============================] - 31s 12ms/step - loss: 1.3301 - accuracy: 0.5768 - val_loss: 1.2733 - val_accuracy: 0.5792\n",
            "Epoch 6/30\n",
            "2665/2665 [==============================] - 31s 12ms/step - loss: 1.2128 - accuracy: 0.6130 - val_loss: 1.1581 - val_accuracy: 0.6168\n",
            "Epoch 7/30\n",
            "2665/2665 [==============================] - 32s 12ms/step - loss: 1.1120 - accuracy: 0.6411 - val_loss: 1.0394 - val_accuracy: 0.6521\n",
            "Epoch 8/30\n",
            "2665/2665 [==============================] - 32s 12ms/step - loss: 1.0553 - accuracy: 0.6594 - val_loss: 1.0312 - val_accuracy: 0.6784\n",
            "Epoch 9/30\n",
            "2665/2665 [==============================] - 32s 12ms/step - loss: 0.9901 - accuracy: 0.6822 - val_loss: 0.9650 - val_accuracy: 0.6822\n",
            "Epoch 10/30\n",
            "2665/2665 [==============================] - 32s 12ms/step - loss: 0.9431 - accuracy: 0.6919 - val_loss: 0.8788 - val_accuracy: 0.7093\n",
            "Epoch 11/30\n",
            "2665/2665 [==============================] - 32s 12ms/step - loss: 0.9120 - accuracy: 0.7086 - val_loss: 0.7698 - val_accuracy: 0.7448\n",
            "Epoch 12/30\n",
            "2665/2665 [==============================] - 32s 12ms/step - loss: 0.8784 - accuracy: 0.7146 - val_loss: 0.9327 - val_accuracy: 0.7335\n",
            "Epoch 13/30\n",
            "2665/2665 [==============================] - 32s 12ms/step - loss: 0.8305 - accuracy: 0.7314 - val_loss: 0.9042 - val_accuracy: 0.7012\n",
            "Epoch 14/30\n",
            "2665/2665 [==============================] - 32s 12ms/step - loss: 0.8054 - accuracy: 0.7390 - val_loss: 0.8597 - val_accuracy: 0.7170\n",
            "Epoch 15/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.7804 - accuracy: 0.7493 - val_loss: 0.6838 - val_accuracy: 0.7717\n",
            "Epoch 16/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.7637 - accuracy: 0.7563 - val_loss: 0.8911 - val_accuracy: 0.7380\n",
            "Epoch 17/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.7463 - accuracy: 0.7631 - val_loss: 0.6459 - val_accuracy: 0.7880\n",
            "Epoch 18/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.7341 - accuracy: 0.7661 - val_loss: 0.7293 - val_accuracy: 0.7521\n",
            "Epoch 19/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.7036 - accuracy: 0.7745 - val_loss: 0.6456 - val_accuracy: 0.7921\n",
            "Epoch 20/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.6898 - accuracy: 0.7827 - val_loss: 0.6355 - val_accuracy: 0.7908\n",
            "Epoch 21/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.6689 - accuracy: 0.7887 - val_loss: 0.6122 - val_accuracy: 0.8008\n",
            "Epoch 22/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.6616 - accuracy: 0.7909 - val_loss: 0.8217 - val_accuracy: 0.7780\n",
            "Epoch 23/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.6379 - accuracy: 0.8027 - val_loss: 0.7205 - val_accuracy: 0.7504\n",
            "Epoch 24/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.6274 - accuracy: 0.8007 - val_loss: 0.5223 - val_accuracy: 0.8386\n",
            "Epoch 25/30\n",
            "2665/2665 [==============================] - 32s 12ms/step - loss: 0.6224 - accuracy: 0.8068 - val_loss: 0.5945 - val_accuracy: 0.8279\n",
            "Epoch 26/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.6095 - accuracy: 0.8113 - val_loss: 0.8894 - val_accuracy: 0.7843\n",
            "Epoch 27/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.6059 - accuracy: 0.8116 - val_loss: 0.7128 - val_accuracy: 0.7685\n",
            "Epoch 28/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.6091 - accuracy: 0.8180 - val_loss: 0.6158 - val_accuracy: 0.7805\n",
            "Epoch 29/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.6001 - accuracy: 0.8161 - val_loss: 0.5081 - val_accuracy: 0.8288\n",
            "Epoch 30/30\n",
            "2665/2665 [==============================] - 33s 12ms/step - loss: 0.5959 - accuracy: 0.8235 - val_loss: 0.6612 - val_accuracy: 0.7833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFXk8eAfa6W5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "d256cc94-520b-486a-bbf2-331ce9330d80"
      },
      "source": [
        "%load_ext tensorboard\n",
        "!tensorboard dev upload --logdir logs"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Upload started and will continue reading any new data as it's added\n",
            "to the logdir. To stop uploading, press Ctrl-C.\n",
            "View your TensorBoard live at: https://tensorboard.dev/experiment/RetMQKdPQwCMglxF6OGoYA/\n",
            "\n",
            "Upload stopped. View your TensorBoard at https://tensorboard.dev/experiment/RetMQKdPQwCMglxF6OGoYA/\n",
            "Exception ignored in: <bound method PyRecordReader.<lambda> of <tensorflow.python.pywrap_tensorflow_internal.PyRecordReader; proxy of <Swig Object of type 'tensorflow::io::PyRecordReader *' at 0x7f630cbbc570> >>\n",
            "Traceback (most recent call last):\n",
            "  File \"/tensorflow-2.1.0/python3.6/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 903, in <lambda>\n",
            "    __del__ = lambda self: None\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}