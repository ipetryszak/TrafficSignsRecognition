{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traffic_sign_recognition.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skorpiom/traffic_sign_rec/blob/master/traffic_sign_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfjxHdfIeA4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf sample_data\n",
        "!rm -rf train_and_valid_signs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WyfMCT8tZdr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e639bbf9-a298-48e0-86fe-8c68fa4cf02c"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.io.parsers import read_csv\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "np.set_printoptions(precision = 6, suppress = True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMSPpKQze6zy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a37d5fb1-2dd4-4105-8d56-e264710131f6"
      },
      "source": [
        "!wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB-Training_fixed.zip\n",
        "!unzip -q GTSRB-Training_fixed.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-28 20:24:07--  https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB-Training_fixed.zip\n",
            "Resolving sid.erda.dk (sid.erda.dk)... 130.225.104.13\n",
            "Connecting to sid.erda.dk (sid.erda.dk)|130.225.104.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 187490228 (179M) [application/zip]\n",
            "Saving to: ‘GTSRB-Training_fixed.zip’\n",
            "\n",
            "GTSRB-Training_fixe 100%[===================>] 178.80M  23.9MB/s    in 8.4s    \n",
            "\n",
            "2019-12-28 20:24:16 (21.2 MB/s) - ‘GTSRB-Training_fixed.zip’ saved [187490228/187490228]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKtwh6NQtbct",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "70d99968-e687-4879-baf5-f712c3a6b2a1"
      },
      "source": [
        "base_dir = './GTSRB/Training'\n",
        "raw_no_of_files = {}\n",
        "classes = []\n",
        "for n in range(0,43):\n",
        "  if n<10:\n",
        "    classes.append(\"0000\"+str(n))\n",
        "  else:\n",
        "    classes.append(\"000\"+str(n))\n",
        "\n",
        "for dir in classes:\n",
        "  raw_no_of_files[dir] = len(os.listdir(os.path.join(base_dir,dir)))\n",
        "\n",
        "raw_no_of_files.items()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('00000', 151), ('00001', 1501), ('00002', 1501), ('00003', 961), ('00004', 1321), ('00005', 1261), ('00006', 301), ('00007', 961), ('00008', 961), ('00009', 991), ('00010', 1351), ('00011', 901), ('00012', 1411), ('00013', 1441), ('00014', 541), ('00015', 421), ('00016', 301), ('00017', 751), ('00018', 811), ('00019', 151), ('00020', 241), ('00021', 241), ('00022', 271), ('00023', 361), ('00024', 181), ('00025', 1021), ('00026', 421), ('00027', 181), ('00028', 361), ('00029', 181), ('00030', 301), ('00031', 541), ('00032', 181), ('00033', 481), ('00034', 301), ('00035', 811), ('00036', 271), ('00037', 151), ('00038', 1381), ('00039', 211), ('00040', 241), ('00041', 181), ('00042', 181)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDk2VufBzHX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = './train_and_valid_signs'\n",
        "dirs_train = []\n",
        "dirs_valid = []\n",
        "\n",
        "train_dir = os.path.join(data_dir,'train') #katalog treningowy\n",
        "valid_dir = os.path.join(data_dir,'valid') #katalog walidacyjny\n",
        "\n",
        "for n in range(0,43):\n",
        "  dirs_train.append(os.path.join(train_dir,classes[n])) #sciezki z katalogami docelowymi zbior treningowy\n",
        "\n",
        "for n in range(0,43):\n",
        "  dirs_valid.append(os.path.join(valid_dir,classes[n])) #sciezki z katalogami docelowymi zbior walidacyjny\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "  os.mkdir(data_dir)\n",
        "  \n",
        "for directory in (train_dir,valid_dir):\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)\n",
        "\n",
        "for directory in dirs_train:\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)\n",
        "\n",
        "for directory in dirs_valid:\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5q60TwSrB3L",
        "colab_type": "text"
      },
      "source": [
        "#DISPLAY INDICATED SIGN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ATvJIdIeJHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "359f450c-7c6a-469c-ec30-1cdb571f8514"
      },
      "source": [
        "img_path = os.path.join('./GTSRB','Training','00000','00001_00010.ppm')\n",
        "print(img_path)\n",
        "img = image.load_img(img_path)\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(img)\n",
        "plt.grid(False)\n",
        "plt.axis(False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./GTSRB/Training/00000/00001_00010.ppm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 35.5, 34.5, -0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEYAAABECAYAAAA85kOPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQn3GdKH/BmqWm/FvbuoeAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu6phs3CilvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c491acda-4e85-4c50-8981-e1b3bacf1b92"
      },
      "source": [
        "sign_fnames = []\n",
        "for ind in range(0,43):\n",
        "  sign_fnames.append(os.listdir(os.path.join(base_dir,classes[ind])))  \n",
        "\n",
        "print('00000 liczba obiektow: ',len(sign_fnames[0]))\n",
        "print('00001 liczba obiektow: ',len(sign_fnames[1]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00000 liczba obiektow:  151\n",
            "00001 liczba obiektow:  1501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVuWmzKiqw39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,fname in enumerate(sign_fnames):\n",
        "  for j,name in enumerate(fname):\n",
        "    if j<=0.8*int(np.floor(len(fname))):\n",
        "      src = os.path.join(base_dir,classes[i],name)\n",
        "      dst = os.path.join(dirs_train[i],name)\n",
        "      shutil.copyfile(src,dst)\n",
        "    if 0.8*int(np.floor(len(fname))) < j <= len(fname):\n",
        "      src = os.path.join(base_dir,classes[i],name)\n",
        "      dst = os.path.join(dirs_valid[i],name)\n",
        "      shutil.copyfile(src,dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ42aaDc84nH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "f8065737-5acd-41ce-c817-f920ee0f8e10"
      },
      "source": [
        "print('00000 zbior treningowy ',len(os.listdir(dirs_train[0])))\n",
        "print('00000 zbior walidacyjny ',len(os.listdir(dirs_valid[0])))\n",
        "\n",
        "print('00001 zbior treningowy ',len(os.listdir(dirs_train[1])))\n",
        "print('00001 zbior walidacyjny ',len(os.listdir(dirs_valid[1])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00000 zbior treningowy  121\n",
            "00000 zbior walidacyjny  30\n",
            "00001 zbior treningowy  1201\n",
            "00001 zbior walidacyjny  300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCWoQ5IY_R6U",
        "colab_type": "text"
      },
      "source": [
        "#AUGMENTACJA DANYCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3naRxdW84cN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "edaf02f6-689f-4932-b53e-1f37c519bc82"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range = 40,\n",
        "    rescale = 1./255.,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest'\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale = 1./255.) #przeskalowanie danych\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
        "                                                    target_size=(32,32),\n",
        "                                                    batch_size = 8,\n",
        "                                                    class_mode='categorical')\n",
        "valid_generator = train_datagen.flow_from_directory(directory = valid_dir,\n",
        "                                                    target_size=(32,32),\n",
        "                                                    batch_size = 8,\n",
        "                                                    class_mode='categorical')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 21319 images belonging to 43 classes.\n",
            "Found 5321 images belonging to 43 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN2J_L_X33Tl",
        "colab_type": "text"
      },
      "source": [
        "#TRANSFER LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uXxVNn_32r0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "1c059560-971a-4c04-fef0-aa13915086a3"
      },
      "source": [
        "conv_base = VGG16(weights = 'imagenet', include_top = False, input_shape=(32,32,3))\n",
        "conv_base.trainable = False\n",
        "\n",
        "def print_layers(model):\n",
        "  for layer in model.layers:\n",
        "    print(f'layer_name {layer.name:13} trainable: {layer.trainable}')\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name =='block5_conv1':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "\n",
        "print_layers(conv_base)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer_name input_7       trainable: False\n",
            "layer_name block1_conv1  trainable: False\n",
            "layer_name block1_conv2  trainable: False\n",
            "layer_name block1_pool   trainable: False\n",
            "layer_name block2_conv1  trainable: False\n",
            "layer_name block2_conv2  trainable: False\n",
            "layer_name block2_pool   trainable: False\n",
            "layer_name block3_conv1  trainable: False\n",
            "layer_name block3_conv2  trainable: False\n",
            "layer_name block3_conv3  trainable: False\n",
            "layer_name block3_pool   trainable: False\n",
            "layer_name block4_conv1  trainable: False\n",
            "layer_name block4_conv2  trainable: False\n",
            "layer_name block4_conv3  trainable: False\n",
            "layer_name block4_pool   trainable: False\n",
            "layer_name block5_conv1  trainable: True\n",
            "layer_name block5_conv2  trainable: True\n",
            "layer_name block5_conv3  trainable: True\n",
            "layer_name block5_pool   trainable: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlJ0Lkp-59lc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "0a662bd2-2333-4ad7-aa08-249efa84e971"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units = 1024, activation = 'relu'))\n",
        "model.add(layers.Dense(units = 43, activation = 'softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 43)                44075     \n",
            "=================================================================\n",
            "Total params: 15,284,075\n",
            "Trainable params: 569,387\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuJvZM-p7GsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFNHu_l17XT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(generator=train_generator,\n",
        "                              epochs = 50,\n",
        "                              validation_data = valid_generator,\n",
        "                              callbacks = [tensorboard])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp0doLYEQZA2",
        "colab_type": "text"
      },
      "source": [
        "#BUDOWA MODELU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyBNveOWNq_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "b9f2f08f-5acc-4954-b221-9381a3cc147b"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(3,3),activation='relu',input_shape=(32, 32, 3)))\n",
        "model.add(layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units=2048, activation='relu'))\n",
        "model.add(layers.Dense(units=43, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 2048)              8390656   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 43)                88107     \n",
            "=================================================================\n",
            "Total params: 8,867,179\n",
            "Trainable params: 8,867,179\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcmPligmU4ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adadelta', #optimizers.RMSprop(lr=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQeEJIniXv1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf logs\n",
        "!mkdir logs\n",
        "tensorboard = TensorBoard(log_dir='logs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3bHf7yaXxbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "df45e97e-68e8-4500-d6b1-55862d3c13f7"
      },
      "source": [
        "history = model.fit_generator(generator=train_generator,\n",
        "                              epochs = 50,\n",
        "                              validation_data = valid_generator,\n",
        "                              callbacks = [tensorboard])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 2665 steps, validate for 666 steps\n",
            "Epoch 1/50\n",
            "2665/2665 [==============================] - 30s 11ms/step - loss: 3.6894 - accuracy: 0.0551 - val_loss: 3.5876 - val_accuracy: 0.0562\n",
            "Epoch 2/50\n",
            "2665/2665 [==============================] - 29s 11ms/step - loss: 3.5438 - accuracy: 0.0576 - val_loss: 3.5264 - val_accuracy: 0.0588\n",
            "Epoch 3/50\n",
            "1013/2665 [==========>...................] - ETA: 15s - loss: 3.5241 - accuracy: 0.0558"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-f87bdd5f2fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                               \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                               callbacks = [tensorboard])\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m   \u001b[0mconstant_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \"\"\"\n\u001b[1;32m    821\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \"\"\"\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFXk8eAfa6W5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "34ae45d9-9bc5-43f3-cf7d-ab7662901624"
      },
      "source": [
        "%load_ext tensorboard\n",
        "!tensorboard dev upload --logdir logs"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Upload started and will continue reading any new data as it's added\n",
            "to the logdir. To stop uploading, press Ctrl-C.\n",
            "View your TensorBoard live at: https://tensorboard.dev/experiment/E4NWoTRVSbmfra1IVKYM8Q/\n",
            "\n",
            "Upload stopped. View your TensorBoard at https://tensorboard.dev/experiment/E4NWoTRVSbmfra1IVKYM8Q/\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}